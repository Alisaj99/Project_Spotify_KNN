{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:27:53.750957100Z",
     "start_time": "2024-05-26T20:27:53.750433Z"
    }
   },
   "outputs": [],
   "source": [
    "#Importieren der relevanten Bibliotheken für das Projekt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:27:53.773413900Z",
     "start_time": "2024-05-26T20:27:53.756332100Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:27:53.773413900Z",
     "start_time": "2024-05-26T20:27:53.761060800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:27:53.793160500Z",
     "start_time": "2024-05-26T20:27:53.773413900Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set a base path for data, which can be configured by the user\n",
    "base_data_path = \"path_to_data_folder\"  # User should update this path as per their local setup\n",
    "\n",
    "# Function to load data from CSV files\n",
    "def load_data(file_name):\n",
    "    file_path = os.path.join(base_data_path, file_name)\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Load datasets\n",
    "tracks_df = load_data(\"spotify_tracks.csv\")\n",
    "albums_df = load_data(\"spotify_albums.csv\")\n",
    "artists_df = load_data(\"spotify_artists.csv\")\n",
    "audio_features_df = load_data(\"low_level_audio_features.csv\")\n",
    "lyrics_features_df = load_data(\"lyrics_features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:27:53.819203100Z",
     "start_time": "2024-05-26T20:27:53.787216400Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot distributions of features to assist in feature selection\n",
    "numerical_features = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'speechiness', 'tempo', 'valence']\n",
    "for feature in numerical_features:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.histplot(tracks_df[feature], kde=True)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:27:54.201717500Z",
     "start_time": "2024-05-26T20:27:53.793160500Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:27:55.563730700Z",
     "start_time": "2024-05-26T20:27:54.201717500Z"
    }
   },
   "outputs": [],
   "source": [
    "import streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:27:55.587408200Z",
     "start_time": "2024-05-26T20:27:55.568914700Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data for training and validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model on training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model on test data\n",
    "predictions = knn.predict(X_test)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:27:55.587408200Z",
     "start_time": "2024-05-26T20:27:55.571801900Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:27:55.645962900Z",
     "start_time": "2024-05-26T20:27:55.589239200Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:27:55.908970Z",
     "start_time": "2024-05-26T20:27:55.649473200Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:27:55.919534100Z",
     "start_time": "2024-05-26T20:27:55.916026500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:40:32.966965600Z",
     "start_time": "2024-05-26T20:40:23.670181700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keine Features verfügbar zum Trainieren des Modells.\n",
      "Tracks DataFrame:\n",
      "   Unnamed: 0  acousticness                album_id  \\\n",
      "0           0         0.294  0D3QufeCudpQANOR7luqdr   \n",
      "1           1         0.863  1bcqsH5UyTBzmh9YizdsBE   \n",
      "2           2         0.750  4tKijjmxGClg4JOLAyo2qE   \n",
      "3           3         0.763  6FeJF5r8roonnKraJxr4oB   \n",
      "4           4         0.770  4tKijjmxGClg4JOLAyo2qE   \n",
      "\n",
      "                                        analysis_url  \\\n",
      "0  https://api.spotify.com/v1/audio-analysis/5qlj...   \n",
      "1  https://api.spotify.com/v1/audio-analysis/3VAX...   \n",
      "2  https://api.spotify.com/v1/audio-analysis/1L3Y...   \n",
      "3  https://api.spotify.com/v1/audio-analysis/6aCe...   \n",
      "4  https://api.spotify.com/v1/audio-analysis/1Vo8...   \n",
      "\n",
      "                   artists_id  \\\n",
      "0  ['3mxJuHRn2ZWD5OofvJtDZY']   \n",
      "1  ['4xWMewm6CYMstu0sPgd9jJ']   \n",
      "2  ['3hYaK5FF3YAglCj5HZgBnP']   \n",
      "3  ['2KQsUB9DRBcJk17JWX1eXD']   \n",
      "4  ['3hYaK5FF3YAglCj5HZgBnP']   \n",
      "\n",
      "                                   available_markets country  danceability  \\\n",
      "0  ['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...      BE         0.698   \n",
      "1  ['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...      BE         0.719   \n",
      "2                                             ['GB']      BE         0.466   \n",
      "3  ['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...      BE         0.719   \n",
      "4                                             ['GB']      BE         0.460   \n",
      "\n",
      "   disc_number  duration_ms  ...  \\\n",
      "0          1.0     235584.0  ...   \n",
      "1          1.0     656960.0  ...   \n",
      "2          1.0     492840.0  ...   \n",
      "3          1.0     316578.0  ...   \n",
      "4          1.0     558880.0  ...   \n",
      "\n",
      "                                         preview_url speechiness    tempo  \\\n",
      "0  https://p.scdn.co/mp3-preview/1b05a902da3a251d...      0.0262  115.018   \n",
      "1  https://p.scdn.co/mp3-preview/d8140736a6131cb5...      0.9220  115.075   \n",
      "2  https://p.scdn.co/mp3-preview/c8af28fb15185b18...      0.9440   79.565   \n",
      "3  https://p.scdn.co/mp3-preview/7629b8e9f31f6e9b...      0.9380  112.822   \n",
      "4  https://p.scdn.co/mp3-preview/32be593c0eb82868...      0.9430   81.260   \n",
      "\n",
      "   time_signature                                         track_href  \\\n",
      "0             4.0  https://api.spotify.com/v1/tracks/5qljLQuKnNJf...   \n",
      "1             3.0  https://api.spotify.com/v1/tracks/3VAX2MJdmdqA...   \n",
      "2             4.0  https://api.spotify.com/v1/tracks/1L3YAhsEMrGV...   \n",
      "3             3.0  https://api.spotify.com/v1/tracks/6aCe9zzoZmCo...   \n",
      "4             4.0  https://api.spotify.com/v1/tracks/1Vo802A38tPF...   \n",
      "\n",
      "   track_name_prev  track_number                                   uri  \\\n",
      "0         track_14           1.0  spotify:track:5qljLQuKnNJf4F4vfxQB0V   \n",
      "1          track_3           3.0  spotify:track:3VAX2MJdmdqARLSU5hPMpm   \n",
      "2          track_4           4.0  spotify:track:1L3YAhsEMrGVvCgDXj2TYn   \n",
      "3          track_9           1.0  spotify:track:6aCe9zzoZmCojX7bbgKKtf   \n",
      "4          track_2           2.0  spotify:track:1Vo802A38tPFHmje1h91um   \n",
      "\n",
      "   valence   type  \n",
      "0   0.6220  track  \n",
      "1   0.5890  track  \n",
      "2   0.0850  track  \n",
      "3   0.5330  track  \n",
      "4   0.0906  track  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "Albums DataFrame:\n",
      "   Unnamed: 0 album_type               artist_id  \\\n",
      "0           0     single  3DiDSECUqqY1AuBP8qtaIa   \n",
      "1           1      album  6s1pCNXcbdtQJlsnM1hRIA   \n",
      "2           2     single  5YjfNaHq05WrwldRe1QSBc   \n",
      "3           3     single  2G9Vc16JCpnZmK4uGH46Fa   \n",
      "4           4     single  2dwM9OcE4c3Ph1UBINSodx   \n",
      "\n",
      "                                   available_markets  \\\n",
      "0  ['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...   \n",
      "1  ['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...   \n",
      "2  ['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...   \n",
      "3  ['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...   \n",
      "4  ['AD', 'AE', 'AR', 'AT', 'AU', 'BE', 'BG', 'BH...   \n",
      "\n",
      "                                       external_urls  \\\n",
      "0  {'spotify': 'https://open.spotify.com/album/1g...   \n",
      "1  {'spotify': 'https://open.spotify.com/album/4K...   \n",
      "2  {'spotify': 'https://open.spotify.com/album/7n...   \n",
      "3  {'spotify': 'https://open.spotify.com/album/6p...   \n",
      "4  {'spotify': 'https://open.spotify.com/album/1X...   \n",
      "\n",
      "                                                href                      id  \\\n",
      "0  https://api.spotify.com/v1/albums/1gAM7M4rBwEb...  1gAM7M4rBwEbSPeAQR2nx1   \n",
      "1  https://api.spotify.com/v1/albums/4KfJZV7WfolY...  4KfJZV7WfolYlxBzOTo66s   \n",
      "2  https://api.spotify.com/v1/albums/7nLYY7uAVUb5...  7nLYY7uAVUb57kpd7tZxnS   \n",
      "3  https://api.spotify.com/v1/albums/6p20Rt4x2Qn5...  6p20Rt4x2Qn5mUMRi1s6pj   \n",
      "4  https://api.spotify.com/v1/albums/1XeoOqC1q7U2...  1XeoOqC1q7U2iyLEQJ64cu   \n",
      "\n",
      "                                              images  \\\n",
      "0  [{'height': 640, 'url': 'https://i.scdn.co/ima...   \n",
      "1  [{'height': 640, 'url': 'https://i.scdn.co/ima...   \n",
      "2  [{'height': 640, 'url': 'https://i.scdn.co/ima...   \n",
      "3  [{'height': 640, 'url': 'https://i.scdn.co/ima...   \n",
      "4  [{'height': 640, 'url': 'https://i.scdn.co/ima...   \n",
      "\n",
      "                                                name release_date  \\\n",
      "0                              If I Ain't Got You EP   2019-02-08   \n",
      "1  Shostakovich Symphony No.5 - Four Romances on ...   2019-03-01   \n",
      "2                                       Take My Bass   2019-03-14   \n",
      "3                                Hypnotizing (Are U)   2016-11-16   \n",
      "4                                           Sunshine   2018-07-20   \n",
      "\n",
      "  release_date_precision  total_tracks                track_id  \\\n",
      "0                    day             6  2iejTMy9XZ8Gaae0aQ2yl0   \n",
      "1                    day             8  1WQfghEjszJJ4H8MAWrQ2C   \n",
      "2                    day             1  3jJKj4QTK3v18ZSwpk7AcV   \n",
      "3                    day             1  1xGtDafUZbHyYC3Xarcbrj   \n",
      "4                    day             1  0gWtsXvXOzAT6FtM3ur8in   \n",
      "\n",
      "  track_name_prev                                   uri   type  \n",
      "0        track_32  spotify:album:1gAM7M4rBwEbSPeAQR2nx1  album  \n",
      "1        track_11  spotify:album:4KfJZV7WfolYlxBzOTo66s  album  \n",
      "2        track_15  spotify:album:7nLYY7uAVUb57kpd7tZxnS  album  \n",
      "3        track_46  spotify:album:6p20Rt4x2Qn5mUMRi1s6pj  album  \n",
      "4        track_10  spotify:album:1XeoOqC1q7U2iyLEQJ64cu  album  \n",
      "Artists DataFrame:\n",
      "   Unnamed: 0  artist_popularity  followers  \\\n",
      "0           0                 44      23230   \n",
      "1           1                 22        313   \n",
      "2           2                 26       1596   \n",
      "3           3                 31        149   \n",
      "4           4                 21         11   \n",
      "\n",
      "                                              genres                      id  \\\n",
      "0  ['sertanejo', 'sertanejo pop', 'sertanejo trad...  4mGnpjhqgx4RUdsIJiURdo   \n",
      "1                                                 []  1dLnVku4VQUOLswwDFvRc9   \n",
      "2                                ['danish pop rock']  6YVY310fjfUzKi8hiqR7iK   \n",
      "3                             ['uk alternative pop']  2VElyouiCfoYPDJluzwJwK   \n",
      "4                                 ['french baroque']  4agVy03qW8juSysCTUOuDI   \n",
      "\n",
      "                  name                track_id track_name_prev    type  \n",
      "0        Juliano Cezar  0wmDmAILuW9e2aRttkl4aC         track_9  artist  \n",
      "1       The Grenadines  4wqwj0gA8qPZKLl5WVqXml        track_30  artist  \n",
      "2              Gangway  1bFqWDbvHmZe2f4Nf9qaD8        track_38  artist  \n",
      "3                FADES  3MFSUBAidPzRBbIS7BDj1S        track_34  artist  \n",
      "4  Jean-Pierre Guignon  2r3q57FhxdsCyYr0kuDq4b        track_26  artist  \n",
      "Audio Features DataFrame:\n",
      "   Unnamed: 0  Chroma_1  Chroma_10  Chroma_11  Chroma_12  Chroma_2  Chroma_3  \\\n",
      "0           0  0.438296   0.472769   0.427441   0.436688  0.467697  0.493862   \n",
      "1           1  0.596605   0.368288   0.285263   0.302211  0.905805  0.510909   \n",
      "2           2  0.505224   0.500420   0.506773   0.488258  0.498356  0.573582   \n",
      "3           3  0.525690   0.666469   0.579492   0.498920  0.598528  0.631578   \n",
      "4           4  0.632214   0.503698   0.496942   0.611532  0.634613  0.697265   \n",
      "\n",
      "   Chroma_4  Chroma_5  Chroma_6  ...  Tonnetz_4  Tonnetz_5  Tonnetz_6  \\\n",
      "0  0.512244  0.568658  0.560524  ...   0.018434  -0.001759  -0.006392   \n",
      "1  0.221708  0.311248  0.491277  ...   0.046941   0.005665  -0.026928   \n",
      "2  0.690761  0.742858  0.686282  ...  -0.006929   0.004968   0.008947   \n",
      "3  0.501693  0.500468  0.587101  ...  -0.027382  -0.009689   0.001402   \n",
      "4  0.557012  0.530836  0.444279  ...   0.003728  -0.002780  -0.010120   \n",
      "\n",
      "        ZCR  entropy_energy  spectral_bandwith  spectral_centroid  \\\n",
      "0  0.067966      -89.113389        2564.247669        3558.400706   \n",
      "1  0.047308     -127.945239        2370.181495        1499.689590   \n",
      "2  0.058463     -238.285176        2973.294736        1543.550034   \n",
      "3  0.080547     -148.785733        2716.749483        3017.248824   \n",
      "4  0.084945     -176.618314        3096.692876        2118.686992   \n",
      "\n",
      "   spectral_rollOff_max  spectral_rollOff_min                track_id  \n",
      "0           4508.506071            367.831109  19YEk4OVQZn3GfoxbpNrU6  \n",
      "1           3647.394611            230.165275  6zJms3MX11Qu1IKF44LoRW  \n",
      "2           5623.349330            187.290534  1WugzepXsLjnsM0K4UaWYc  \n",
      "3           5799.931595            160.940693  1pSlTbCrUJ9rmwj5CNNrX4  \n",
      "4           6560.018666            229.131948  5yruvWJs3mL00w4slpCVzN  \n",
      "\n",
      "[5 rows x 209 columns]\n",
      "Lyrics Features DataFrame:\n",
      "   Unnamed: 0  mean_syllables_word  mean_words_sentence  n_sentences  n_words  \\\n",
      "0           0                -1.00                -1.00           -1       -1   \n",
      "1           1                 1.10                 5.65           31      326   \n",
      "2           2                 1.37                 4.77           74      532   \n",
      "3           3                 1.95                 3.38           72      430   \n",
      "4           4                 1.16                 2.99           68      368   \n",
      "\n",
      "   sentence_similarity                track_id  vocabulary_wealth  \n",
      "0            -1.000000  5KIfHjHI5NIsPHNt58qua0              -1.00  \n",
      "1             0.043011  13keyz9ikBe6ZpRasw7l4X               0.45  \n",
      "2             0.050352  1WugzepXsLjnsM0K4UaWYc               0.59  \n",
      "3             0.028560  2MO6oEAlMKcsfI8xP3yoy8               0.49  \n",
      "4             0.047849  1i4St7fmSUE9nB3R9n8fol               0.47  \n",
      "\n",
      "Audio Features DataFrame Columns:\n",
      "Index(['Unnamed: 0', 'Chroma_1', 'Chroma_10', 'Chroma_11', 'Chroma_12',\n",
      "       'Chroma_2', 'Chroma_3', 'Chroma_4', 'Chroma_5', 'Chroma_6',\n",
      "       ...\n",
      "       'Tonnetz_4', 'Tonnetz_5', 'Tonnetz_6', 'ZCR', 'entropy_energy',\n",
      "       'spectral_bandwith', 'spectral_centroid', 'spectral_rollOff_max',\n",
      "       'spectral_rollOff_min', 'track_id'],\n",
      "      dtype='object', length=209)\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "# Adding a slider to control the number of recommendations\n",
    "num_recommendations = st.slider(\"Number of recommendations\", min_value=1, max_value=10, value=5)\n",
    "\n",
    "# Generate recommendations based on the slider\n",
    "distances, indices = knn.kneighbors(scaled_features, n_neighbors=num_recommendations)\n",
    "recommended_songs = tracks_df.iloc[indices[0]].dropna()\n",
    "\n",
    "# Display song recommendations with additional details\n",
    "st.write(\"Recommended Songs:\")\n",
    "for idx in indices[0]:\n",
    "    song = tracks_df.iloc[idx]\n",
    "    st.write(f\"{song['song_title']} by {song['artist_name']} - Genre: {song['genre']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:41:36.037756900Z",
     "start_time": "2024-05-26T20:41:35.990194400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'acousticness', 'album_id', 'analysis_url', 'artists_id',\n",
      "       'available_markets', 'country', 'danceability', 'disc_number',\n",
      "       'duration_ms', 'energy', 'href', 'id', 'instrumentalness', 'key',\n",
      "       'liveness', 'loudness', 'lyrics', 'mode', 'name', 'playlist',\n",
      "       'popularity', 'preview_url', 'speechiness', 'tempo', 'time_signature',\n",
      "       'track_href', 'track_name_prev', 'track_number', 'uri', 'valence',\n",
      "       'type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Spaltennamen in tracks_df anzeigen\n",
    "print(tracks_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:41:40.943544300Z",
     "start_time": "2024-05-26T20:41:40.914526900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Chroma_1', 'Chroma_10', 'Chroma_11', 'Chroma_12',\n",
      "       'Chroma_2', 'Chroma_3', 'Chroma_4', 'Chroma_5', 'Chroma_6',\n",
      "       ...\n",
      "       'Tonnetz_4', 'Tonnetz_5', 'Tonnetz_6', 'ZCR', 'entropy_energy',\n",
      "       'spectral_bandwith', 'spectral_centroid', 'spectral_rollOff_max',\n",
      "       'spectral_rollOff_min', 'track_id'],\n",
      "      dtype='object', length=209)\n"
     ]
    }
   ],
   "source": [
    "#Anzeigen der Spaltennamen audio_features_df\n",
    "print(audio_features_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T11:39:35.235189300Z",
     "start_time": "2024-05-27T11:39:35.067895800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spalten in tracks_df: Index(['Unnamed: 0', 'acousticness', 'album_id', 'analysis_url', 'artist_id',\n",
      "       'available_markets', 'country', 'danceability', 'disc_number',\n",
      "       'duration_ms', 'energy', 'href', 'track_id', 'instrumentalness', 'key',\n",
      "       'liveness', 'loudness', 'lyrics', 'mode', 'name', 'playlist',\n",
      "       'popularity', 'preview_url', 'speechiness', 'tempo', 'time_signature',\n",
      "       'track_href', 'track_name_prev', 'track_number', 'uri', 'valence',\n",
      "       'type'],\n",
      "      dtype='object')\n",
      "Spalten in artists_df: Index(['Unnamed: 0', 'artist_popularity', 'followers', 'genres', 'artist_id',\n",
      "       'name', 'track_id', 'track_name_prev', 'type'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m artists_df\u001B[38;5;241m.\u001B[39mrename(columns\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124martistid\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124martist_id\u001B[39m\u001B[38;5;124m'\u001B[39m}, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# erneut zu mergen\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m merged_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mmerge(tracks_df, artists_df, on\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124martist_id\u001B[39m\u001B[38;5;124m'\u001B[39m, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(merged_df\u001B[38;5;241m.\u001B[39minfo())\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mast\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:183\u001B[0m, in \u001B[0;36mmerge\u001B[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001B[0m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    169\u001B[0m     op \u001B[38;5;241m=\u001B[39m _MergeOperation(\n\u001B[0;32m    170\u001B[0m         left_df,\n\u001B[0;32m    171\u001B[0m         right_df,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    181\u001B[0m         validate\u001B[38;5;241m=\u001B[39mvalidate,\n\u001B[0;32m    182\u001B[0m     )\n\u001B[1;32m--> 183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m op\u001B[38;5;241m.\u001B[39mget_result(copy\u001B[38;5;241m=\u001B[39mcopy)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:883\u001B[0m, in \u001B[0;36m_MergeOperation.get_result\u001B[1;34m(self, copy)\u001B[0m\n\u001B[0;32m    880\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindicator:\n\u001B[0;32m    881\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleft, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mright \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indicator_pre_merge(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleft, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mright)\n\u001B[1;32m--> 883\u001B[0m join_index, left_indexer, right_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_join_info()\n\u001B[0;32m    885\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_and_concat(\n\u001B[0;32m    886\u001B[0m     join_index, left_indexer, right_indexer, copy\u001B[38;5;241m=\u001B[39mcopy\n\u001B[0;32m    887\u001B[0m )\n\u001B[0;32m    888\u001B[0m result \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_merge_type)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1133\u001B[0m, in \u001B[0;36m_MergeOperation._get_join_info\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1129\u001B[0m     join_index, right_indexer, left_indexer \u001B[38;5;241m=\u001B[39m _left_join_on_index(\n\u001B[0;32m   1130\u001B[0m         right_ax, left_ax, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mright_join_keys, sort\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msort\n\u001B[0;32m   1131\u001B[0m     )\n\u001B[0;32m   1132\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1133\u001B[0m     (left_indexer, right_indexer) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_join_indexers()\n\u001B[0;32m   1135\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mright_index:\n\u001B[0;32m   1136\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleft) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1105\u001B[0m, in \u001B[0;36m_MergeOperation._get_join_indexers\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_join_indexers\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[npt\u001B[38;5;241m.\u001B[39mNDArray[np\u001B[38;5;241m.\u001B[39mintp], npt\u001B[38;5;241m.\u001B[39mNDArray[np\u001B[38;5;241m.\u001B[39mintp]]:\n\u001B[0;32m   1104\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"return the join indexers\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1105\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m get_join_indexers(\n\u001B[0;32m   1106\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mleft_join_keys, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mright_join_keys, sort\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msort, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhow\n\u001B[0;32m   1107\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1703\u001B[0m, in \u001B[0;36mget_join_indexers\u001B[1;34m(left_keys, right_keys, sort, how)\u001B[0m\n\u001B[0;32m   1698\u001B[0m \u001B[38;5;66;03m# get left & right join labels and num. of levels at each location\u001B[39;00m\n\u001B[0;32m   1699\u001B[0m mapped \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1700\u001B[0m     _factorize_keys(left_keys[n], right_keys[n], sort\u001B[38;5;241m=\u001B[39msort, how\u001B[38;5;241m=\u001B[39mhow)\n\u001B[0;32m   1701\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(left_keys))\n\u001B[0;32m   1702\u001B[0m )\n\u001B[1;32m-> 1703\u001B[0m zipped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mmapped)\n\u001B[0;32m   1704\u001B[0m llab, rlab, shape \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mlist\u001B[39m(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m zipped)\n\u001B[0;32m   1706\u001B[0m \u001B[38;5;66;03m# get flat i8 keys from label lists\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1700\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m   1696\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _get_no_sort_one_missing_indexer(left_n, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   1698\u001B[0m \u001B[38;5;66;03m# get left & right join labels and num. of levels at each location\u001B[39;00m\n\u001B[0;32m   1699\u001B[0m mapped \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m-> 1700\u001B[0m     _factorize_keys(left_keys[n], right_keys[n], sort\u001B[38;5;241m=\u001B[39msort, how\u001B[38;5;241m=\u001B[39mhow)\n\u001B[0;32m   1701\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(left_keys))\n\u001B[0;32m   1702\u001B[0m )\n\u001B[0;32m   1703\u001B[0m zipped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mmapped)\n\u001B[0;32m   1704\u001B[0m llab, rlab, shape \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mlist\u001B[39m(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m zipped)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2499\u001B[0m, in \u001B[0;36m_factorize_keys\u001B[1;34m(lk, rk, sort, how)\u001B[0m\n\u001B[0;32m   2492\u001B[0m     rlab \u001B[38;5;241m=\u001B[39m rizer\u001B[38;5;241m.\u001B[39mfactorize(\n\u001B[0;32m   2493\u001B[0m         rk\u001B[38;5;241m.\u001B[39mto_numpy(na_value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mlk\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mnumpy_dtype), mask\u001B[38;5;241m=\u001B[39mrk\u001B[38;5;241m.\u001B[39misna()\n\u001B[0;32m   2494\u001B[0m     )\n\u001B[0;32m   2495\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2496\u001B[0m     \u001B[38;5;66;03m# Argument 1 to \"factorize\" of \"ObjectFactorizer\" has incompatible type\u001B[39;00m\n\u001B[0;32m   2497\u001B[0m     \u001B[38;5;66;03m# \"Union[ndarray[Any, dtype[signedinteger[_64Bit]]],\u001B[39;00m\n\u001B[0;32m   2498\u001B[0m     \u001B[38;5;66;03m# ndarray[Any, dtype[object_]]]\"; expected \"ndarray[Any, dtype[object_]]\"\u001B[39;00m\n\u001B[1;32m-> 2499\u001B[0m     llab \u001B[38;5;241m=\u001B[39m rizer\u001B[38;5;241m.\u001B[39mfactorize(lk)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m   2500\u001B[0m     rlab \u001B[38;5;241m=\u001B[39m rizer\u001B[38;5;241m.\u001B[39mfactorize(rk)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m   2501\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m llab\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mdtype(np\u001B[38;5;241m.\u001B[39mintp), llab\u001B[38;5;241m.\u001B[39mdtype\n",
      "File \u001B[1;32mhashtable.pyx:122\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.ObjectFactorizer.factorize\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7288\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_labels\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7194\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "\n",
    "# This section of the code is responsible for loading the data. Please make sure to update the paths according to your local setup.\n",
    "# The following code block performs the exploratory data analysis (EDA), which is crucial for understanding the distribution of musical features.\n",
    "# The model validation block is used to assess the accuracy of our KNN model, ensuring its reliability before deployment.\n",
    "# Streamlit UI enhancements are included to improve user interaction and provide dynamic control over the number of song recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### In tracks_df ist die ähnliche Spalte artists_id und in artists_df ist sie einfach als id benannt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T11:32:23.364679700Z",
     "start_time": "2024-05-27T11:32:23.292003700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'artists_id'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3790\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3791\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3792\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:152\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:181\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'artists_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 17\u001B[0m\n\u001B[0;32m     14\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Anwendung der Funktion auf die 'artists_id' Spalte und Speichern im 'artist_id'\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m tracks_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124martist_id\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m tracks_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124martists_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(safe_literal_eval)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3891\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3892\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3893\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mget_loc(key)\n\u001B[0;32m   3894\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3895\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3793\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3794\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3795\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3796\u001B[0m     ):\n\u001B[0;32m   3797\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3798\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3799\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3800\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3801\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3802\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3803\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'artists_id'"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def safe_literal_eval(s):\n",
    "    try:\n",
    "        # Versuche den String zu evaluieren\n",
    "        result = ast.literal_eval(s)\n",
    "        # Wenn das Ergebnis eine Liste ist, gib das erste Element zurück, sonst die leere Liste\n",
    "        if isinstance(result, list) and result:\n",
    "            return result[0]\n",
    "        else:\n",
    "            return None  # Wenn die Liste leer ist oder kein Listenformat vorliegt\n",
    "    except:\n",
    "        # Bei jedem Fehler, gib None zurück\n",
    "        return None\n",
    "\n",
    "# Anwendung der Funktion auf die 'artists_id' Spalte und Speichern im 'artist_id'\n",
    "tracks_df['artist_id'] = tracks_df['artists_id'].apply(safe_literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T11:12:38.106351600Z",
     "start_time": "2024-05-27T11:12:38.079680600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracks DF Columns: Index(['Unnamed: 0', 'acousticness', 'album_id', 'analysis_url', 'artists_id',\n",
      "       'available_markets', 'country', 'danceability', 'disc_number',\n",
      "       'duration_ms', 'energy', 'href', 'id', 'instrumentalness', 'key',\n",
      "       'liveness', 'loudness', 'lyrics', 'mode', 'name', 'playlist',\n",
      "       'popularity', 'preview_url', 'speechiness', 'tempo', 'time_signature',\n",
      "       'track_href', 'track_name_prev', 'track_number', 'uri', 'valence',\n",
      "       'type'],\n",
      "      dtype='object')\n",
      "Audio Features DF Columns: Index(['Unnamed: 0', 'Chroma_1', 'Chroma_10', 'Chroma_11', 'Chroma_12',\n",
      "       'Chroma_2', 'Chroma_3', 'Chroma_4', 'Chroma_5', 'Chroma_6',\n",
      "       ...\n",
      "       'Tonnetz_4', 'Tonnetz_5', 'Tonnetz_6', 'ZCR', 'entropy_energy',\n",
      "       'spectral_bandwith', 'spectral_centroid', 'spectral_rollOff_max',\n",
      "       'spectral_rollOff_min', 'track_id'],\n",
      "      dtype='object', length=209)\n",
      "Lyrics Features DF Columns: Index(['Unnamed: 0', 'mean_syllables_word', 'mean_words_sentence',\n",
      "       'n_sentences', 'n_words', 'sentence_similarity', 'track_id',\n",
      "       'vocabulary_wealth'],\n",
      "      dtype='object')\n",
      "Albums DF Columns: Index(['Unnamed: 0', 'album_type', 'artist_id', 'available_markets',\n",
      "       'external_urls', 'href', 'id', 'images', 'name', 'release_date',\n",
      "       'release_date_precision', 'total_tracks', 'track_id', 'track_name_prev',\n",
      "       'uri', 'type'],\n",
      "      dtype='object')\n",
      "Artists DF Columns: Index(['Unnamed: 0', 'artist_popularity', 'followers', 'genres', 'id', 'name',\n",
      "       'track_id', 'track_name_prev', 'type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Überprüfen der Spaltennamen\n",
    "print(\"Tracks DF Columns:\", tracks_df.columns)\n",
    "print(\"Audio Features DF Columns:\", audio_features_df.columns)\n",
    "print(\"Lyrics Features DF Columns:\", lyrics_features_df.columns)\n",
    "print(\"Albums DF Columns:\", albums_df.columns)\n",
    "print(\"Artists DF Columns:\", artists_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T11:12:44.293321700Z",
     "start_time": "2024-05-27T11:12:43.751467Z"
    }
   },
   "outputs": [],
   "source": [
    "# Umbenennen der Spalten für Konsistenz\n",
    "tracks_df = tracks_df.rename(columns={'id': 'track_id', 'artists_id': 'artist_id'})\n",
    "albums_df = albums_df.rename(columns={'id': 'album_id'})\n",
    "artists_df = artists_df.rename(columns={'id': 'artist_id'})\n",
    "# Erklärung: Diese Umbenennungen sorgen für Konsistenz in den Datenframes, wichtig für die Verarbeitung und Analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T11:13:02.821824500Z",
     "start_time": "2024-05-27T11:13:02.767146600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracks DF Columns (after renaming): Index(['Unnamed: 0', 'acousticness', 'album_id', 'analysis_url', 'artist_id',\n",
      "       'available_markets', 'country', 'danceability', 'disc_number',\n",
      "       'duration_ms', 'energy', 'href', 'track_id', 'instrumentalness', 'key',\n",
      "       'liveness', 'loudness', 'lyrics', 'mode', 'name', 'playlist',\n",
      "       'popularity', 'preview_url', 'speechiness', 'tempo', 'time_signature',\n",
      "       'track_href', 'track_name_prev', 'track_number', 'uri', 'valence',\n",
      "       'type'],\n",
      "      dtype='object')\n",
      "Albums DF Columns (after renaming): Index(['Unnamed: 0', 'album_type', 'artist_id', 'available_markets',\n",
      "       'external_urls', 'href', 'album_id', 'images', 'name', 'release_date',\n",
      "       'release_date_precision', 'total_tracks', 'track_id', 'track_name_prev',\n",
      "       'uri', 'type'],\n",
      "      dtype='object')\n",
      "Artists DF Columns (after renaming): Index(['Unnamed: 0', 'artist_popularity', 'followers', 'genres', 'artist_id',\n",
      "       'name', 'track_id', 'track_name_prev', 'type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Sicherstellen, dass die artist_id-Spalte vorhanden ist\n",
    "print(\"Tracks DF Columns (after renaming):\", tracks_df.columns)\n",
    "print(\"Albums DF Columns (after renaming):\", albums_df.columns)\n",
    "print(\"Artists DF Columns (after renaming):\", artists_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hier wird sichergestellt, dass die `artist_id` Spalte korrekt von String zu Liste konvertiert wird, indem fehlerhafte Strings zuerst korrigiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T11:13:16.238931500Z",
     "start_time": "2024-05-27T11:13:13.300885700Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "def safe_literal_eval(s):\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except ValueError:\n",
    "        return []  # Return an empty list if conversion fails\n",
    "tracks_df[\"artist_id\"] = tracks_df[\"artist_id\"].apply(safe_literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.278188800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Funktion zum sicheren Entfernen von Spalten\n",
    "def drop_columns_safely(df, columns):\n",
    "    return df.drop(columns=[col for col in columns if col in df.columns])\n",
    "\n",
    "tracks_df = drop_columns_safely(tracks_df, ['Unnamed: 0', 'analysis_url', 'available_markets', 'country', 'href', 'playlist', 'preview_url', 'track_href', 'track_name_prev', 'uri', 'type'])\n",
    "albums_df = drop_columns_safely(albums_df, ['Unnamed: 0', 'available_markets', 'external_urls', 'href', 'images', 'release_date', 'release_date_precision', 'track_name_prev', 'uri', 'type'])\n",
    "artists_df = drop_columns_safely(artists_df, ['Unnamed: 0', 'genres', 'track_name_prev', 'type'])\n",
    "audio_features_df = drop_columns_safely(audio_features_df, ['Unnamed: 0'])\n",
    "lyrics_features_df = drop_columns_safely(lyrics_features_df, ['Unnamed: 0'])\n",
    "\n",
    "# Auswahl der Features basierend auf der Analyse, welche Merkmale am meisten zur Unterscheidung der Songs beitragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.280949400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Überprüfen der Spaltennamen nach dem Entfernen und Umbenennen\n",
    "print(\"Tracks DF Columns (after removing and renaming):\", tracks_df.columns)\n",
    "print(\"Audio Features DF Columns:\", audio_features_df.columns)\n",
    "print(\"Lyrics Features DF Columns:\", lyrics_features_df.columns)\n",
    "print(\"Albums DF Columns:\", albums_df.columns)\n",
    "print(\"Artists DF Columns:\", artists_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.282957400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Entfernen der Zeile mit fehlendem Künstlernamen\n",
    "artists_df = artists_df.dropna(subset=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.284972900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Umbenennen von artist_id in albums_df, um Konflikte zu vermeiden\n",
    "albums_df = albums_df.rename(columns={'artist_id': 'album_artist_id'})\n",
    "# Erklärung: Diese Umbenennungen sorgen für Konsistenz in den Datenframes, wichtig für die Verarbeitung und Analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.285951Z"
    }
   },
   "outputs": [],
   "source": [
    "# Überprüfen, ob die notwendigen Spalten vorhanden sind\n",
    "print('artist_id in Tracks:', 'artist_id' in tracks_df.columns)\n",
    "print('album_id in Albums:', 'album_id' in albums_df.columns)\n",
    "print('album_artist_id in Albums:', 'album_artist_id' in albums_df.columns)\n",
    "print('artist_id in Artists:', 'artist_id' in artists_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.288976400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sicherstellen, dass die artist_id-Spalte vorhanden ist\n",
    "if 'artist_id' in tracks_df.columns and 'artist_id' in artists_df.columns:\n",
    "    # Schrittweises Zusammenführen der Daten und Ausgabe der Zwischenschritte\n",
    "    merged_df_1 = pd.merge(tracks_df, audio_features_df, on='track_id')\n",
    "    print(\"Merged DF 1 shape:\", merged_df_1.shape)\n",
    "    merged_df_2 = pd.merge(merged_df_1, lyrics_features_df, on='track_id')\n",
    "    print(\"Merged DF 2 shape:\", merged_df_2.shape)\n",
    "    merged_df_3 = pd.merge(merged_df_2, albums_df, on='album_id')\n",
    "    print(\"Merged DF 3 shape:\", merged_df_3.shape)\n",
    "\n",
    "    # Sicherstellen, dass 'artist_id' auch in merged_df_3 vorhanden ist\n",
    "    if 'artist_id' in merged_df_3.columns:\n",
    "        merged_df_4 = pd.merge(merged_df_3, artists_df, on='artist_id')\n",
    "        print(\"Merged DF 4 shape:\", merged_df_4.shape)\n",
    "\n",
    "        # Komplexes Label, dass  auf Tanzbarkeit und Energie basiert\n",
    "        merged_df_4['label'] = merged_df_4['danceability'].astype(str) + '_' + merged_df_4['energy'].astype(str)\n",
    "\n",
    "        # Anzeigen der ersten paar Zeilen mit den neuen Labels\n",
    "        print(merged_df_4[['label', 'danceability', 'energy']].head())\n",
    "    else:\n",
    "        print(\"'artist_id' nicht in merged_df_3 vorhanden.\")\n",
    "else:\n",
    "    print(\"Die notwendige Spalte 'artist_id' ist in einem der DataFrames nicht vorhanden.\")\n",
    "# Erklärung: Diese Umbenennungen sorgen für Konsistenz in den Datenframes, wichtig für die Verarbeitung und Analyse.\n",
    "# Auswahl der Features basierend auf der Analyse, welche Merkmale am meisten zur Unterscheidung der Songs beitragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T20:28:14.522110800Z",
     "start_time": "2024-05-26T20:28:14.289985500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Zusammengeführte Daten als CSV-Datei speichern\n",
    "merged_df_4.to_csv('merged_df_4.csv', index=False)\n",
    "# Erklärung: Diese Umbenennungen sorgen für Konsistenz in den Datenframes, wichtig für die Verarbeitung und Analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.291996800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Relevante Features auswählen\n",
    "features = ['danceability', 'energy', 'tempo', 'valence', 'acousticness', 'instrumentalness', 'liveness', 'speechiness']\n",
    "# Auswahl der Features basierend auf der Analyse, welche Merkmale am meisten zur Unterscheidung der Songs beitragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.293985800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Features und Track IDs extrahieren\n",
    "X = merged_df_4[features]\n",
    "track_ids = merged_df_4['track_id']\n",
    "# Erklärung: Diese Umbenennungen sorgen für Konsistenz in den Datenframes, wichtig für die Verarbeitung und Analyse.\n",
    "# Auswahl der Features basierend auf der Analyse, welche Merkmale am meisten zur Unterscheidung der Songs beitragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.295043800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalisierung der Features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Training des KNN-Modells mit den spezifizierten Features. Dies ist der Kern des Empfehlungssystems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.296493500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalisierte Features in ein DataFrame konvertieren\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=features)\n",
    "X_scaled_df['track_id'] = track_ids\n",
    "# Auswahl der Features basierend auf der Analyse, welche Merkmale am meisten zur Unterscheidung der Songs beitragen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell speichern\n",
    "Das trainierte KNN-Modell wird hier gespeichert, um später in der Streamlit-App geladen zu werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.298519200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Speichern des Scalers für zukünftige Verwendung\n",
    "import pickle\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "# Speicherung des trainierten Modells, um es später in der Streamlit App zu laden und verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.300015700Z"
    }
   },
   "outputs": [],
   "source": [
    "# KNN-Modell trainieren\n",
    "knn = NearestNeighbors(n_neighbors=10, algorithm='ball_tree')\n",
    "knn.fit(X_scaled_df[features])\n",
    "# Training des KNN-Modells mit den spezifizierten Features - der Kern des Empfehlungssystems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.300826100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Modell speichern\n",
    "with open('knn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(knn, f)\n",
    "# Speicherung des trainierten Modells, um es später in der Streamlit App zu laden und verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.302895Z"
    }
   },
   "outputs": [],
   "source": [
    "# Laden der Modelle und Daten\n",
    "scaler = pickle.load(open('scaler.pkl', 'rb'))\n",
    "knn = pickle.load(open('knn_model.pkl', 'rb'))\n",
    "merged_df_4 = pd.read_csv('C:\\\\Users\\\\monaa\\\\Desktop\\\\Seminare & Vorlesungen\\\\Analyseanwendungen\\\\spotify_data\\\\SpotGenTrack\\\\Data Sources\\\\merged_df_4.csv')\n",
    "# Erklärung: Diese Umbenennungen sorgen für Konsistenz in den Datenframes, wichtig für die Verarbeitung und Analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.304304500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature-Auswahl\n",
    "features = ['danceability', 'energy', 'tempo', 'valence', 'acousticness', 'instrumentalness', 'liveness', 'speechiness']\n",
    "# Auswahl der Features basierend auf der Analyse, welche Merkmale am meisten zur Unterscheidung der Songs beitragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.306335700Z"
    }
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "st.title('Spotify Song Recommendation System')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-26T20:28:14.307392600Z"
    }
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Model und Scaler laden\n",
    "scaler = pickle.load(open('scaler.pkl', 'rb'))\n",
    "knn = pickle.load(open('knn_model.pkl', 'rb'))\n",
    "\n",
    "# Daten laden\n",
    "tracks_df = pd.read_csv('path_to_tracks.csv')  # Path needs to be updated with the actual data path\n",
    "\n",
    "# Feature Auswahl für das Model \n",
    "features = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'speechiness', 'tempo', 'valence']\n",
    "tracks_df = tracks_df[features]\n",
    "\n",
    "# Streamlit app interface\n",
    "st.title('Spotify Song Recommendation System')\n",
    "\n",
    "# Song Auswahl\n",
    "genre_choice = st.selectbox('Choose a genre:', options=['All'] + sorted(tracks_df['genre'].unique().tolist()))\n",
    "if genre_choice != 'All':\n",
    "    filtered_tracks = tracks_df[tracks_df['genre'] == genre_choice]\n",
    "else:\n",
    "    filtered_tracks = tracks_df\n",
    "\n",
    "song_choice = st.selectbox('Select a song:', options=filtered_tracks['song_title'].tolist())\n",
    "\n",
    "# Anzeigen der ausgewählten features der songs\n",
    "selected_song_features = filtered_tracks[filtered_tracks['song_title'] == song_choice][features]\n",
    "st.write('Selected Song Features:', selected_song_features)\n",
    "\n",
    "# Normalisierung der features für Vorhersage\n",
    "scaled_features = scaler.transform(selected_song_features)\n",
    "\n",
    "# Generiere Empfehlungen\n",
    "distances, indices = knn.kneighbors(scaled_features)\n",
    "recommended_songs = tracks_df.iloc[indices[0]].dropna()\n",
    "\n",
    "# Zeige Empfehlungen\n",
    "st.write('Recommended Songs:', recommended_songs[['song_title', 'artist_name']])\n",
    "\n",
    "# Run this Streamlit app with the following command:\n",
    "# streamlit run your_script_name.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
